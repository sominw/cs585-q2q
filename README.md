# Q2Q: Improving Relevance of Responses by Converting Queries to Questions

Code can be found at: [https://github.com/sominwadhwa/cs585-q2q](https://github.com/sominwadhwa/cs585-q2q)

This repository contains all the code written for the final project of `COMPSCI 585: Intro to Natural Language Processing (Mohit Iyyer)` in the Fall 2019.

**Authors**: Thivakkar Mahendran, Vincent Pun, Kathryn Ricci, Apurva Bhandari, Somin Wadhwa

## Pre-requisites

The following are a couple of instructions that must be gone through in order to execute different (or all) sections of this project.

1. Clone the project, replacing ``cs585`` with the name of the directory you are creating:

        $ git clone https://github.com/sominwadhwa/cs585-q2q.git cs585
        $ cd drugADR

2. Make sure you have ``python 3.6.x`` running on your local system. If you do, skip this step. In case you don't, head
head [here](https://www.python.org/downloads/).

3. ``virtualenv`` is a tool used for creating isolated 'virtual' python environments. It is advisable to create one here as well (to avoid installing the pre-requisites into the system-root). Do the following within the project directory:

        $ [sudo] pip install virtualenv
        $ virtualenv --system-site-packages cs585
        $ source cs585/bin/activate

To deactivate later, once you're done with the project, just type ``deactivate``.

4. Install the pre-requisites from ``requirements.txt`` & run ``test/init.py`` to check if all the required packages were correctly installed:

        $ pip install -r requirements.txt
        $ python test/init.py

You should see a message - ``Imports successful. Good to go!``

### Note:
Most (almost all) of our training was carried out on GCP/Collab, and we tried our best to compile this repository in a coherent way so that all of the results are reproducible and it is easy to execute our code. However, if you face any issues whatsoever, please feel free to contact any of the authors and we'll be happy to help you set it up!

## Directory Structure

#### Top-Level Structure:

    .
    .
    ├── data                     # Data used and/or generated
    │   ├── dev_q2d.txt
    │   ├── train_q2d.txt
    │   ├── google_queries.txt
    │   ├── squad_queries.txt
    │   ├── hotpot_queries.txt
    ├── preprocessing-src                     # Source Files
    │   ├── __init__.py
    │   ├── get_context.py
    │   ├── preprocess.py
    ├── src                    # Main source files for training
    │   ├── __init__.py
    │   ├── encoderdecoder.py
    │   ├── failure-analysis-ids.py
    │   ├── keras-nmt-baseline-wo-attn.py
    │   ├── train-eval-q2q-w-attn.py     
    ├── attn_ex (<num>).png 
    ├── attn_ex_sp<num>.png
    ├── loss_curve.png                  
    ├── LICENSE
    └── README.md
    .
    .


#### File Descriptions:

- ``/data/dev_q2d.txt``: Dev set of query -> questions from SQuAD dataset.
- ``/data/train_q2d.txt``: Training set of query -> questions from SQuAD dataset
- ``/data/google_queries.txt``: Queries generated by us from the questions obtained from Google's natural language dataset.
- ``/data/squad_queries.txt``: Queries generated by us from the questions obtained from SQuAD dataset.
- ``/data/hotpot_queries.py``: Queries generated by us from the questions obtained from HotpotQA dataset.
-  ``/src/encoderdecoder.py``: Base data file used for organ level classification.
-  ``/src/encoderdecoder.py``: Base data file used for sub-systems level classification.
-  ``/src/encoderdecoder.py`: Base data file used for organ-systems level classification.
- ``/src/encoderdecoder.py``: Prediction of ADR with first level of classification based on anatomical schema -- organ level, 61 classes against 1430 drugs. Generated an output (workbook) in ``/data/o_v2_results.xlsx`` containing the results.
- ``/src/base_osub.py``: Prediction of ADR with second level of classification based on anatomical schema -- sub-systems level, 30 classes against 1430 drugs. Generated an output (workbook) in ``/data/osub_results.xlsx`` containing the results.
- ``/src/base_osys.py``: Prediction of ADR with final level of classification based on anatomical schema -- sub-systems level, 11 classes against 1430 drugs. Generated an output (workbook) in ``/data/osys_results.xlsx`` containing the results.
- ``/src/voting_o.py``: Voting ensemble model at organ level. Generates & stores output ``/data/o_votingModel_results.xlsx``.
- ``/src/voting_osub.py``: Voting ensemble model at sub-systems level. Generates & stores output ``/data/osub_votingModel_results.xlsx``.
- ``/src/voting_osys.py``: Voting ensemble model at organ-system level. Generates & stores output ``/data/osys_votingModel_results.xlsx``.
- ``/test/rand_o.py``: Script to run random-control experiments on organ-level. Generates an output with a compilation of results. ``/data/list_res_organ.sav``.
- ``/test/rand_osub.py``: Script to run random-control experiments on sub-systems level. Generates an output with a compilation of results.``/data/list_res_Sub_Sys.sav``.
- ``/test/rand_osys.py``: Script to run random-control experiments on organ-systems level. Generates an output with a compilation of results.``/data/list_res_S.sav``.

Description/Information about files other than those mentioned up can be directly inferred from the article/paper.
